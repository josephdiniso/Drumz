<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
  | ECE, Virginia Tech | Fall 2021: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Drumz - Virtual Drum Simulator</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Joseph DiNiso, Enzo Saba, Steven Shaumadine</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2021 ECE 4554/5554 Computer Vision: Course Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>

<!-- Please see <a href="http://vision.cs.utexas.edu/projects/adapted_attributes/">this</a> for an example of how to lay out the various details of your project. You may need to provide more details than this, because you will not be submitting an associated paper to accompany the webpage. So the page should be self-contained. -->

<!-- Goal -->
<h3>Abstract</h3>

Our goal is to implement a portable augmented reality drumset. Using computer vision techniques and live webcam footage, we will build a fluid drumset simulator.
<!-- One or two sentences describing the approach you took. One or two sentences on the main result you obtained. -->
<!-- figure -->
<!-- <h3>Teaser figure</h3> -->
<!-- A figure that conveys the main idea behind the project or the main application being addressed. -->
<!-- <br><br> -->
<!-- Main Illustrative Figure  -->
<!-- <div style="text-align: center;"> -->
<!-- <img style="height: 200px;" alt="" src="mainfig.png"> -->
<!-- </div> -->

<br><br>
<!-- Introduction -->
<h3>Introduction</h3>
A portable drum set can be created using computer vision to track a player’s placement and force applied to a surface by
physical drumsticks and output the corresponding sound. The output sounds depend on which surface the drum sticks impact
and the speed at which the player moves the drum sticks to calculate the impact on the surface.

<br><br>
<!-- Approach -->
<h3>Approach</h3>
Our approach is to differentiate between objects with different colors. For example, the drumsticks will both be the
same differentiable color from its surroundings. The different surfaces on the table will represent different drum types
(e.g. bass, snare, etc.) and will be differentiated with different colors in the real world. This allows for our
software to easily detect these different objects and make a contour around them. <br><br>

To determine when a drumstick has hit a surface we will use two main detectors; the first is when the surface is
occluded by the tracked drumstick, and the second is when the drumstick’s downward velocity is 0. The volume of the beat
will be determined by the velocity of the drumstick prior to hitting the surface. <br><br>

Since each object that we wish to detect is a different color we are able to use color thresholding on the image to
create masks for each object and then use contour detection to obtain a bounding box for each of them. This process can
be seen below on a stock image of colored paper. <br>

<img style="height: 300px; display: block; margin-left: auto; margin-right: auto; width: 50%; display:block" alt="" src="thresh.png"><br>
<p style="text-align: center;"><i>Example of thresholding where the image on the left is a stock image
and the image on the right has been thresholded for pink and yellow colors.</i></p> <br>
<img style="height: 300px; width: 300px; display: block; margin-left: auto; margin-right: auto; display:block" alt="" src="contours.png"><br>
<p style="text-align: center"><i>Contour detection and outlining being used on the masked image
</i></p> <br><br>
Using the defined contours, we can determine impact when the tip of the drumstick enters the bounding box of any of the
contours and then stops moving downward. <br><br>

Once a working implementation is complete, we then plan to build onto the idea with the ability to play different
instruments and build in a user interface that allows for the user to select instruments and gives basic instructions on
how the program works.

<!-- Results -->
<h3>Experiments and results</h3>
Our goal for this project is to use as few external sources of code and data as possible. Because we believe that the
data needed for our project is fairly unique, the entirety of data collected will be from our own recordings. We will
however not be implementing all of the code used for the project, we will mainly be using NumPy and OpenCV for our image
processing and application of computer vision algorithms because they run significantly faster than any Python
implementation of our own doing. <br><br>

Data will be collected by simulated intended user actions, such as banging drumsticks on the surfaces and playing
different combinations of notes. In order to have robust testing, we will make sure to test for the various different
edge cases that often occur in computer vision applications such as dark footage, image noise, etc. Successful
implementation would result in smooth audio playing in response to the user’s actions (e.g. when the user hits the
surface with the drumsticks a sound is immediately played, random sounds do not play without cause, etc.). As well, we
would like to test our implementation on other people who did not develop the project and were given limited
instructions as to how it works; this is because we would like to make a user-friendly interface that does not require
much training. <br><br>

Overall, the project will be deemed successful if a fluid drum set simulator can be created that is both fun,
responsive, and can display various different computer vision algorithms such as thresholding, contour detection, motion
and velocity estimation, and collision detection.

<br><br>

<!-- Main Results Figure 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br>

<h3>Qualitative results</h3>
Show several visual examples of inputs/outputs of your system (success cases and failures) that help us better understand your approach.
<br><br>


<div style="text-align: center;">
<img style="height: 300px;" alt="" src="qual_results.png">
</div>
<br><br>

<h3>Conclusion</h3>
This report has described .... Briefly summarize what you have done. 
<br><br>

<h3>References</h3>
Provide a list of references to other work that supported your project.
<br><br> -->


  <hr>
  <footer> 
  <p>© Enzo Saba, Joseph DiNiso, Steven Shaumadine</p>
  </footer>
</div>
</div>

<br><br>

</body></html>